# ========================================
# ENVIRONMENT CONFIGURATION
# ========================================
# IMPORTANT: Copy this file to .env and fill in your actual values!
# DO NOT commit .env file to git (it's already in .gitignore)
#
# Quick Start: See FIRST_TIME_SETUP.md for step-by-step instructions
# API Keys: See API_SETUP_GUIDE.md for how to get all API keys
# Deployment: See COMPLETE_HOSTING_GUIDE.md for hosting options
# ========================================

# Set to "production" for deployed environments, "development" for local dev
# This controls database and storage path auto-detection
ENVIRONMENT=production

# Application Settings
APP_NAME=Farm Data Automation
DEBUG=False
ALLOWED_ORIGINS=http://localhost:3000,http://localhost:8000

# ========================================
# DATABASE CONFIGURATION
# ========================================
# For Local Development: Leave commented out (will auto-use SQLite)
# For Production PostgreSQL: Uncomment and fill in your database URL
# Get from Railway/Render/DigitalOcean when you deploy
# DATABASE_URL=postgresql+asyncpg://user:password@localhost:5432/farm_data_automation

# ========================================
# STORAGE CONFIGURATION
# ========================================
# Path where audio recordings will be stored on the server
# Auto-detects: ./storage/recordings (dev) or /app/storage/recordings (prod)
# Only set this if you need a custom path
# LOCAL_STORAGE_PATH=/app/storage/recordings

# ========================================
# WHISPER TRANSCRIPTION CONFIGURATION
# ========================================
# Choose your transcription method:
# - "local" = FREE local Whisper model (no API key needed, runs on your server)
# - "api" = OpenAI Whisper API (~$0.006/min, faster, requires API key)
WHISPER_MODE=local

# Local Whisper Settings (only used if WHISPER_MODE=local)
# Model options: tiny, base, small, medium, large
# Recommended: "base" for good balance of speed (10-20s) and quality
# Cost: $0 (completely free!)
WHISPER_LOCAL_MODEL=base

# OpenAI Whisper API Settings (only needed if WHISPER_MODE=api)
# Get your API key from https://platform.openai.com/api-keys
# Cost: ~$0.006 per minute of audio
# WHISPER_API_KEY=sk-your_openai_api_key_here
# WHISPER_MODEL=whisper-1

# Groq AI Configuration (REQUIRED - FREE)
# 1. Go to: https://console.groq.com/
# 2. Sign up (free account)
# 3. Go to API Keys â†’ Create API Key
# 4. Copy and paste below (starts with gsk_)
# See API_SETUP_GUIDE.md for detailed instructions
GROQ_API_KEY=gsk_REPLACE_WITH_YOUR_ACTUAL_GROQ_API_KEY
GROQ_MODEL=llama-3.1-70b-versatile
GROQ_TEMPERATURE=0.1

# ========================================
# LEGACY AZURE SERVICES (COMMENTED OUT)
# Kept for reference during migration
# Can be removed after confirming new services work
# ========================================

# # Azure Storage Configuration
# # Get from Azure Portal -> Storage Account -> Access Keys
# AZURE_STORAGE_CONNECTION_STRING=DefaultEndpointsProtocol=https;AccountName=your_account;AccountKey=your_key;EndpointSuffix=core.windows.net
# AZURE_STORAGE_CONTAINER_NAME=voice-recordings

# # Azure Speech Services Configuration
# # Get from Azure Portal -> Cognitive Services -> Speech
# AZURE_SPEECH_KEY=your_speech_key_here
# AZURE_SPEECH_REGION=eastus

# # Azure OpenAI Configuration
# # Get from Azure Portal -> Azure OpenAI Service
# AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com/
# AZURE_OPENAI_KEY=your_openai_key_here
# AZURE_OPENAI_DEPLOYMENT_NAME=gpt-4
# AZURE_OPENAI_API_VERSION=2024-02-15-preview

# ========================================
# MICROSOFT DYNAMICS 365 CONFIGURATION (REQUIRED)
# ========================================
# Used for syncing animal data to bioTrack+ (Dynamics 365)
#
# IMPORTANT: Follow AZURE_SETUP_QUICK_GUIDE.md for step-by-step instructions
#
# You need 3 values from Azure Portal:
#   1. Application (client) ID - From App Registration overview
#   2. Directory (tenant) ID - From App Registration overview
#   3. Client Secret - Created in "Certificates & secrets"
#
# After getting these values, also run:
#   python scripts/quick_update_creds.py "CLIENT_ID" "TENANT_ID" "CLIENT_SECRET"
#
DYNAMICS_BASE_URL=https://yourorg.crm3.dynamics.com
DYNAMICS_CLIENT_ID=REPLACE_WITH_YOUR_APPLICATION_CLIENT_ID
DYNAMICS_CLIENT_SECRET=REPLACE_WITH_YOUR_CLIENT_SECRET
DYNAMICS_TENANT_ID=REPLACE_WITH_YOUR_TENANT_ID

# ========================================
# REDIS CONFIGURATION (Future Feature)
# ========================================
# Redis URL for background job processing
# Currently not used - processing is done synchronously
# Uncomment when implementing background task queue
# REDIS_URL=redis://localhost:6379/0

# ========================================
# SECURITY SETTINGS (REQUIRED)
# ========================================
# SECRET_KEY: CRITICAL - Generate a unique random key!
#
# Run this command to generate:
#   python -c "import secrets; print(secrets.token_urlsafe(32))"
#
# Copy the output and paste below
# NEVER share this key or commit it to git!
SECRET_KEY=REPLACE_WITH_YOUR_GENERATED_SECRET_KEY
ALGORITHM=HS256
ACCESS_TOKEN_EXPIRE_MINUTES=30
